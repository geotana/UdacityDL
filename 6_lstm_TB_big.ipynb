{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_lstm-TB-big.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Y5tapX3kpcqZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/geotana/UdacityDL/blob/master/6_lstm_TB_big.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "8tQJd2YSCfWR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "D7tqLMoKF6uq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Deep Learning\n",
        "=============\n",
        "\n",
        "Assignment 6\n",
        "------------\n",
        "\n",
        "After training a skip-gram model in `5_word2vec.ipynb`, the goal of this notebook is to train a LSTM character model over [Text8](http://mattmahoney.net/dc/textdata) data."
      ]
    },
    {
      "metadata": {
        "id": "4eErTCTybtph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Problem 2\n",
        "---------\n",
        "\n",
        "We want to train a LSTM over bigrams, that is pairs of consecutive characters like 'ab' instead of single characters like 'a'. Since the number of possible bigrams is large, feeding them directly to the LSTM using 1-hot encodings will lead to a very sparse representation that is very wasteful computationally.\n",
        "\n",
        "a- Introduce an embedding lookup on the inputs, and feed the embeddings to the LSTM cell instead of the inputs themselves.\n",
        "\n",
        "b- Write a bigram-based LSTM, modeled on the character LSTM above.\n",
        "\n",
        "c- Introduce Dropout. For best practices on how to use Dropout in LSTMs, refer to this [article](http://arxiv.org/abs/1409.2329).\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "1VijdTxF6NPq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "18.5.15 検証結果が明らかにおかしい。\n",
        "原因予想\n",
        "h  r r a r r r a r r r a r r r a r r r a r r r \n",
        "1 学習データが非常に偏っている   => No\n",
        "\n",
        "2 推論部分のロジックがおかしい\n",
        "\n",
        "3 ab２文字にした、同じデータセットが2回回った => Yes Fixed\n",
        "\n",
        "18.5.16 状況関わらず　\n",
        "\n",
        "原因予想\n",
        "・lossがマイナスなので、根本がおかしい。Graph周り。==> 推論のインプットとアウトプを突き合わせみる 問題なし！？\n",
        "\n",
        "Average loss at step 1500: -775.086458 learning rate: 10.000000\n",
        "Minibatch perplexity: 0.00\n",
        "Validation set perplexity: 0.09\n",
        "inp [' or what by joe peac', ' some places such as'] ans ['r what by joe peacot', 'ome places such as c'] pre ['rererererererererere', 'rererererererererere']\n",
        "inp ['ott and writings by ', ' clearwater feature '] ans ['t and writings by fr', 'learwater feature re'] pre ['clclclclclclclclclcl', 'clclclclclclclclclcl']\n",
        "\n",
        "全然学習しない。\n",
        "\n",
        "18.6.21\n",
        "学習しない原因は、ネットにあるかも\n",
        "オリジナル：27文字を 27次元の1-Hot Vecで表現\n",
        "中間層は64\n",
        "10文字の並びで学習\n",
        "\n",
        "bigram版：2文字合わせて786次元を128に圧縮\n",
        "中間層は64 ==>中間層　128*2で試す\n",
        "\n",
        "実質20文字の並びで学習\n",
        "\n",
        " ==>中間層　128*2で試す\n",
        " 依然損失関数がマイナスで、増加していく。おかしい\n",
        " \n",
        " ==> unr 5で試す　１０文字の並びでの学習に相当\n",
        " 変わる兆候なし\n",
        "\n",
        "18.6.24\n",
        "forumを読んで気がついたが、このネットワークは分類問題である。\n",
        "しかし、出力が1ーHotVecになっていないので、損失関数としてクロスエントロピーを使うのが不適切である。\n",
        "解決方法\n",
        "1）出力が、N次元の点だとして、回帰問題のように、2点間の、2乗距離の和をとる\n",
        "➡️学習が進まない。\n",
        "unr = 10 * 2\n",
        "num_nodes = 64*4\n",
        "としても大差なし\n",
        "\n",
        "2）出力を1-HotVecにして比較する\n"
      ]
    },
    {
      "metadata": {
        "id": "6nscy0BCo6l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "884a4c48-d1ef-4874-d563-b0b31ce18be1"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/ColabData/\n",
        "!dpkg -l  software-properties-common python-software-properties module-init-tools google-drive-ocamlfuse fuse"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'drive/ColabData/': No such file or directory\n",
            "Desired=Unknown/Install/Remove/Purge/Hold\n",
            "| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\n",
            "|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\n",
            "||/ Name           Version      Architecture Description\n",
            "+++-==============-============-============-=================================\n",
            "un  software-prope <none>       <none>       (no description available)\n",
            "\u001b[1mdpkg-query:\u001b[0m no packages found matching python-software-properties\n",
            "\u001b[1mdpkg-query:\u001b[0m no packages found matching module-init-tools\n",
            "\u001b[1mdpkg-query:\u001b[0m no packages found matching google-drive-ocamlfuse\n",
            "\u001b[1mdpkg-query:\u001b[0m no packages found matching fuse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6YGw1TtCyp7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "76355b45-9be2-4f4f-f526-ea1af762e812"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools  2>&1 > /dev/null\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse  2>&1 > /dev/null\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MvEblsgEXxrd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "147d581c-68d2-45a3-88cf-21ad1fec3f4a"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function #@title デフォルトのタイトル テキスト\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import zipfile\n",
        "import pdb #pdb.set_trace()\n",
        "from six.moves import range\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RJ-o3UBUFtCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "a23363f5-dc38-4c3a-fb15-55da08d52754"
      },
      "cell_type": "code",
      "source": [
        "def maybe_download(filename, expected_bytes):\n",
        "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "  if not os.path.exists(\"./drive/ColabData/\"+filename):\n",
        "    filename, _ = urlretrieve('http://mattmahoney.net/dc/' + filename, \"./drive/ColabData/\" + filename)\n",
        "  else:\n",
        "    filename = \"./drive/ColabData/\" + filename\n",
        "  statinfo = os.stat(filename)\n",
        "  if statinfo.st_size == expected_bytes:\n",
        "    print('Found and verified %s' % filename)\n",
        "  else:\n",
        "    print(statinfo.st_size)\n",
        "    raise Exception('Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
        "  return filename\n",
        "\n",
        "def read_data(filename):\n",
        "  with zipfile.ZipFile(filename) as f:\n",
        "    name = f.namelist()[0]\n",
        "    data = tf.compat.as_str(f.read(name))\n",
        "  return data\n",
        "\n",
        "filename = maybe_download('text8.zip', 31344016)\n",
        "text = read_data(filename)\n",
        "print('Data size %d' % len(text))\n",
        "\n",
        "def cutprint(ltext):\n",
        "  print(len(ltext))\n",
        "  print(ltext[0:10])\n",
        "  print(ltext[10:20])\n",
        "  print(ltext[20:50])\n",
        "\n",
        "valid_size = 1000\n",
        "valid_text = text[:valid_size]\n",
        "cutprint(valid_text)\n",
        "\n",
        "train_text = text[valid_size:]\n",
        "cutprint(train_text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found and verified ./drive/ColabData/text8.zip\n",
            "Data size 100000000\n",
            "1000\n",
            " anarchism\n",
            " originate\n",
            "d as a term of abuse first use\n",
            "99999000\n",
            "ons anarch\n",
            "ists advoc\n",
            "ate social relations based upo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ga2CYACE-ghb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a small validation set."
      ]
    },
    {
      "metadata": {
        "id": "Zdw6i4F8glpp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utility functions to map characters to vocabulary IDs and back."
      ]
    },
    {
      "metadata": {
        "id": "gAL1EECXeZsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "603d842c-3852-4029-dd40-8b2195683e89"
      },
      "cell_type": "code",
      "source": [
        "final_embeddings_np_voc_em = np.load('./drive/ColabData/final_embeddings.npy')\n",
        "# voc -> vocabulary size\n",
        "# em -> embeddings\n",
        "print(\"final_embeddings.shape\",final_embeddings_np_voc_em.shape)\n",
        "\n",
        "embedding_size = 128 # Dimension of the embedding vector.\n",
        "import pickle\n",
        "with open('./drive/ColabData/dictionary.pickle', mode='rb') as f:\n",
        "  dictionary = pickle.load(f)\n",
        "\n",
        "def char2ab_vec_np_em_1(char1,char2):  #2文字からnp_em_1 [ [0.1] [0.15]...  ]\n",
        "  vocabulary_size = 728 # num of ab bc ...\n",
        "  ab_seqnum = dictionary[ char1 + char2]\n",
        "  ab_np_voc_1 = np.zeros((vocabulary_size,1))  \n",
        "  ab_np_voc_1[ab_seqnum][0] = 1.0   # 1-hot vector\n",
        "  return (final_embeddings_np_voc_em.T @ ab_np_voc_1)\n",
        "\n",
        "with open('./drive/ColabData/reverse_dictionary.pickle', mode='rb') as f:\n",
        "  reverse_dictionary = pickle.load(f)\n",
        "    \n",
        "def em_vec2ab(np_em_1): #em vectorから文字列を返す\n",
        "  argmax_1 = np.argmax( final_embeddings_np_voc_em @ np_em_1, axis = 0)\n",
        "#   pdb.set_trace()\n",
        "  return reverse_dictionary[argmax_1[0]]\n",
        "  \n",
        "print( em_vec2ab(char2ab_vec_np_em_1('q','u')), \"|\", em_vec2ab( char2ab_vec_np_em_1('i','s')) )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_embeddings.shape (728, 128)\n",
            "qu | is\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lFwoyygOmWsL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to generate a training batch for the LSTM model."
      ]
    },
    {
      "metadata": {
        "id": "d9wMtjy5hCj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7bb6d196-13bf-4137-e55f-6a9153e2e7c3"
      },
      "cell_type": "code",
      "source": [
        "batch_size= 64 #64\n",
        "num_unrollings= 20 #10\n",
        "\n",
        "class BatchGenerator(object):\n",
        "  def __init__(self, text, batch_size, num_unrollings):\n",
        "    self._text = text\n",
        "    self._text_size = len(text)\n",
        "    self._batch_size = batch_size\n",
        "    self._num_unrollings = num_unrollings\n",
        "    segment = self._text_size // batch_size   # 1batch当たりのテキストサイズ \n",
        "    self._cursor_L64 = [ offset * segment for offset in range(batch_size)] #segmentのスタート位置\n",
        "    self._last_batch = self._next_batch() #np (bs,em)\n",
        "  \n",
        "  def _next_batch(self): #ここは良い。順番にab cd 。。。と返している\n",
        "    \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
        "    batch_np_bs_em = np.empty((0, embedding_size),dtype=np.float)\n",
        "\n",
        "    for b in range(self._batch_size):\n",
        "       a_pos = self._cursor_L64[b] % self._text_size #折り返し\n",
        "       b_pos =  (a_pos + 1) % self._text_size #折り返し \n",
        "       batch_np_bs_em = np.append(batch_np_bs_em,\n",
        "           char2ab_vec_np_em_1( self._text[a_pos], self._text[b_pos]) .T, axis=0)\n",
        "#        pdb.set_trace()\n",
        "       self._cursor_L64[b] =(b_pos  + 1) %  self._text_size #segment内の次のテキスト位置をセット abを考慮、折り返し あり\n",
        "\n",
        "    return batch_np_bs_em # ab Word Vector\n",
        "  \n",
        "  def next(self): #あれ。ここも良さそう。\n",
        "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
        "    the last batch of the previous array, followed by num_unrollings new ones.\n",
        "    \"\"\"\n",
        "    batches = [self._last_batch] #最初のab vecをnp_bs_emの先頭に LIST of np(bs,em)) \n",
        "    # batches[0] = ['on', 'of']  、batches[1] = ['s ', ' t'] 繋がっている\n",
        "  \n",
        "    for step in range(self._num_unrollings):\n",
        "      batches.append(self._next_batch()) #後ろにunrolling分だけ追加\n",
        "#     pdb.set_trace()  \n",
        "    self._last_batch = batches[-1] #LIST末尾の要素をセット\n",
        "    return batches #cursorから始まるunrolling+1個分のnp(bs,em)のLISTを返す\n",
        "  \n",
        "def np_bs_em2ab_li_bs(np_bs_em): # bs個のem vectorからbs個の文字列を返す\n",
        "\n",
        "  ab_li_bs=[]\n",
        "  for b in range(np_bs_em.shape[0]): \n",
        "    x_np_em = np_bs_em.T [ : , b]\n",
        "    ab_li_bs.append(em_vec2ab( x_np_em[ : , np.newaxis]))\n",
        "  return ab_li_bs\n",
        "  \n",
        "def characters(probabilities): #1-hot vecから1文字にして、bs個のリストを返す\n",
        "#   Turn a 1-hot encoding or a probability distribution over the possible\n",
        "#   characters back into its (most likely) character representation.　\n",
        "  x = [id2char(c) for c in np.argmax(probabilities, 1)]\n",
        "  return x\n",
        "  \n",
        "# def batches2string(batches): # np_bs_emのリストから文字列を返す　オリジナルなら [unr個] bs個のリスト\n",
        "#   \"\"\"Convert a sequence of batches back into their (most likely) string\n",
        "#   representation.\"\"\"\n",
        "# #  fi-embed.T x ab_vec -> voc vect 最大の要素から reverse dict\n",
        "#   string = []  #bs個の要素を持つ縦ベクトルのnum_unrollings個の要素を持つList\n",
        " \n",
        "#   for step in range(len(batches)):\n",
        "#     string.append( np_bs_em2ab_li_bs( batches[step] ))\n",
        "#   return string\n",
        "\n",
        "def batches2string(batches):\n",
        "  \"\"\"Convert a sequence of batches back into their (most likely) string\n",
        "  representation.\"\"\"\n",
        "  s = [''] * batches[0].shape[0] # bs 個の空の要素を持ったリストを作る\n",
        "  for b in batches: #unr個の繰り返し\n",
        "    s = [''.join(x) for x in zip(s, np_bs_em2ab_li_bs(b))]\n",
        "#     s = [''.join(x) for x in zip(s, characters(b))]\n",
        "  return s\n",
        "\n",
        "#next()の呼び出しで次々に教師データのバッチサイズ分の文字emベクトルを返すようなオブジェクトを作る\n",
        "train_batches = BatchGenerator(train_text, batch_size, num_unrollings) \n",
        "\n",
        "#正しく、nextで訓練データが取得できるか確かめる #精査すべし！！\n",
        "print(\"1:\", batches2string( train_batches.next() ) ) # train_batches.next()はunrolling+1個分のnp(bs,em)のLIST\n",
        "print(\"2:\", batches2string( train_batches.next() ) ) # これをunrolling+1個 x bs個の文字で返す\n",
        "# 1: [['on', 'n ', 'gn', ' d', 'of', 'at', 'st', 'ck'], ['s ', 'fr', 'if', 'ru', ' t', ' l', ' d', 'y '], ['an', 'om', 'ic', 'gs', 'he', 'ea', 'ai', 'ri'], ['ar', ' t', 'an', ' c', ' o', 'st', 'ly', 'ca'], ['ch', 'he', 't ', 'on', 'ri', ' n', ' c', 'rd'], ['is', ' n', 'th', 'fu', 'gi', 'ot', 'ol', 'o '], ['ts', 'at', 'an', 'si', 'na', ' p', 'le', 'th'], [' a', 'io', ' i', 'on', 'l ', 'ar', 'ge', 'is'], ['dv', 'na', 'n ', ' i', 'do', 'li', ' n', ' c'], ['oc', 'l ', 'je', 'na', 'cu', 'am', 'ew', 'la'], ['at', 'me', 'rs', 'bi', 'me', 'en', 'sp', 'ss']]\n",
        "# 2: [['at', 'me', 'rs', 'bi', 'me', 'en', 'sp', 'ss'], ['e ', 'di', 'ey', 'li', 'nt', 't ', 'ap', 'ic'], ['so', 'a ', ' a', 'ty', ' f', 's ', 'er', ' i'], ['ci', 'an', 'nd', ' t', 'ax', 'op', ' i', 'nc'], ['al', 'd ', ' g', 'o ', ' m', 'po', 'n ', 'lu'], [' r', 'fr', 'ue', 'or', 'ac', 'si', 'th', 'de'], ['el', 'om', 'rn', 'ie', 'hi', 'ti', 'e ', 's '], ['at', ' p', 'se', 'nt', 'ne', 'on', 'un', 'lu'], ['io', 're', 'y ', ' o', 's ', ' a', 'it', 'cy'], ['ns', 'si', 'ha', 'ne', 'wi', ' s', 'ed', ' w'], [' b', 'de', 's ', 'se', 'th', 'ub', ' s', 'in']]\n",
        "  \n",
        "# ons anarch\n",
        "# ists advoc\n",
        "# ate social\n",
        "\n",
        "valid_batches = BatchGenerator(valid_text, 1, 1)\n",
        "print(\"3:\", batches2string( valid_batches.next() ) )\n",
        "print(\"4:\", batches2string( valid_batches.next() ) )\n",
        "# 3: [[' a'], ['na']]\n",
        "# 4: [['na'], ['rc']]\n",
        "\n",
        "# train:  ons anarchists advocate social relations based upon voluntary as\n",
        "# valid:   anarchism originated as a term of abuse first used against earl\n",
        "\n",
        "# オリジナルの実行 bs=8\n",
        "# ['ons anarchi', 'n from the ', 'gnificant t', ' drugs conf', 'of the orig', 'at least no', 'st daily co', 'cky ricardo']\n",
        "# ['ists advoca', ' national m', 'than in jer', 'fusion inab', 'ginal docum', 'ot parliame', 'ollege news', 'o this clas']\n",
        "# [' a']\n",
        "# ['an']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: ['ons anarchists advocate social relations b', 'when military governments failed to revive', 'lleria arches national park photographic v', ' abbeys and monasteries index sacred desti', 'married urraca princess of castile daughte', 'hel and richard baer h provided a detailed', 'y and liturgical language among jews manda', 'ay opened for passengers in december one n', 'tion from the national media and from pres', 'migration took place during the one nine e', 'new york other well known manufacturers of', 'he boeing seven six seven a widebody jet w', 'e listed with a gloss covering some of the', 'eber has probably been one of the most inf', 'o be made to recognize single acts of meri', 'yer who received the first card from the d', 'ore significant than in jersey and guernse', 'a fierce critic of the poverty and social ', ' two six eight in signs of humanity vol th', 'aristotle s uncaused cause so aquinas come', 'ity can be lost as in denaturalization and', ' and intracellular ice formation solution ', 'tion of the size of the input usually meas', 'dy to pass him a stick to pull him out but', 'f certain drugs confusion inability to ori', 'at it will take to complete an operation c', 'e convince the priest of the mistakes of a', 'ent told him to name it fort des moines th', 'ampaign and barred attempts by his opponen', 'rver side standard formats for mailboxes i', 'ious texts such as esoteric christianity a', 'o capitalize on the growing popularity of ', 'a duplicate of the original document fax m', 'gh ann es d hiver one nine eight zero one ', 'ine january eight march eight listing of a', 'ross zero the lead character lieutenant sh', 'cal theories classical mechanics and speci', 'ast instance the non gm comparison maize c', ' dimensional analysis fundamental applicat', 'most holy mormons believe the configuratio', 't s support or at least not parliament s o', 'u is still disagreed upon by historians an', 'e oscillating system example rlc circuit f', 'o eight subtypes based on the whole genome', 'of italy languages the official language o', 's the tower commission at this point presi', 'klahoma press one nine three two one one t', 'erprise linux suse linux enterprise server', 'ws becomes the first daily college newspap', 'et in a nazi concentration camp lewis has ', 'the fabian society nehru wished the econom', 'etchy to relatively stiff from flat to tig', ' sharman networks sharman s sydney based b', 'ised emperor hirohito to begin negotiation', 'ting in political initiatives the lesotho ', 'd neo latin most of these authors wrote in', 'th risky riskerdoo ricky ricardo this clas', 'encyclopedic overview of mathematics prese', 'fense the air component of arm is represen', 'duating from acnm accredited programs must', 'treet grid centerline external links bbc o', 'ations more than any other state modern da', 'appeal of devotional buddhism especially r', 'si have made such devices possible the sys']\n",
            "2: [' based upon voluntary association of auton', 've the economy and suppress escalating ter', ' virtual tour of arches national park arch', 'tinations abbeys of france sacred destinat', 'ter of alfonso viii king of castile and le', 'ed description of the camp s workings duri', 'daeans and some christians and is still sp', ' nine zero two on the night of friday one ', 'esidential candidate john f kennedy despit', ' eight zero s with the arrival of thousand', 'of bass amplifiers or loudspeakers include', ' was introduced at around the same time as', 'heir deeds a significance is attached to t', 'nfluential users of the word in its social', 'rit or meritorious service the required ac', ' deal may be known as eldest hand or as fo', 'sey has maintained light industry as a hig', 'l stratification of victorian society thro', 'three michel balat and janice deledalle rh', 'mes to the same conclusion that god exists', 'nd gained as in naturalization supranation', 'n effects are caused by concentration of s', 'asured in bits using the most efficient al', 'ut she refuses unless he declare his devot', 'rient oneself later signs lethargy decreas', ' cannot be bounded in advance see unbounde', ' a pious life the novel the one two zero d', 'the original origin of the name des moines', 'ents to run campaign advertisements for th', ' include maildir and mbox several prominen', ' and the work of g i gurdjieff a variety o', 'f disco with the album discovery or disco ', ' machines with additional electronic featu', 'e nine eight six and cartographies schizoa', ' all days days february nine is the four z', 'shin kudo played by kenichi suzumura is a ', 'cial relativity classical mechanics and sp', ' crop had also been treated with environme', 'ations of probability and statistics nine ', 'ion of the continents was different before', ' opposition a subtle but important differe', 'and linguists it is generally accepted as ', ' full mathematical definition most harmoni', 'me that are each geographically distinct t', ' of italy is standard italian a direct des', 'sident reagan said he had not been informe', ' th printing one nine eight nine isbn zero', 'er debian and the version sgi offers on th', 'aper in the united states one eight eight ', 's explained why the film hasn t been relea', 'omy of india to be partially capitalist bu', 'ightly curled and so on process a modern k', ' boss nikki hemming and associate kevin be', 'ons to end world war ii after the beginnin', 'o congress for democracy lcd won the major', 'in their various vernaculars as well as in', 'assic includes lucy winding the cello s tu', 'sented in clear simple language hazewinkel', 'ented by the command of military aviation ', 'st pass the same certifying exam administe', ' on this day may two seven may two nine ap', 'day montana became montana territory in on', ' represented by the pure land this rich co', 'ystemic advantages of mpls such as the abi']\n",
            "3: [' ana']\n",
            "4: ['narc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K8f67YXaDr4C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Simple LSTM Model."
      ]
    },
    {
      "metadata": {
        "id": "Q5rxZK6RDuGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "b87ef441-4a79-426e-c8fa-1cec35018df1"
      },
      "cell_type": "code",
      "source": [
        "vocabulary_size = embedding_size #1-hotの代わりab_em_vectorを使う\n",
        "vocabulary_size0 = vocabulary_size  #　オリジナルを保管\n",
        "\n",
        "num_nodes = 64*4 #64\n",
        "import tensorflow as tf\n",
        "embedding_size = 128 # Dimension of the embedding vector.\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "\n",
        "  big_x = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes * 4], -0.1, 0.1), name=\"big_x\")\n",
        "  big_m = tf.Variable(tf.truncated_normal([num_nodes, num_nodes * 4], -0.1, 0.1), name=\"big_m\")\n",
        "  big_b = tf.Variable(tf.zeros([1, num_nodes * 4]), name=\"big_b\")\n",
        "  \n",
        "  # Variables saving state across unrollings.\n",
        "  saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False,name=\"saved_output\")\n",
        "  saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False,name=\"saved_state\")\n",
        "  \n",
        "  # Classifier weights and biases.\n",
        "  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1),name=\"w\")\n",
        "  b = tf.Variable(tf.zeros([vocabulary_size]),name=\"b\")\n",
        "  \n",
        "  \n",
        "  # Definition of the cell computation.\n",
        "  def lstm_cell(i, o, state): #receiving input, hidden(t-1) and state(t-1)\n",
        "    \n",
        "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
        "    Note that in this formulation, we omit the various connections between the\n",
        "    previous state and the gates.\"\"\"\n",
        "    \n",
        "    with tf.name_scope(\"lstm_cell\"):\n",
        "  \n",
        "      split0, split1, split2, split3 = tf.split(tf.matmul(i, big_x) + tf.matmul(o, big_m) + big_b, num_or_size_splits=4, axis=1)\n",
        "      input_gate = tf.sigmoid(split0)\n",
        "      forget_gate = tf.sigmoid(split1)\n",
        "      update = split2\n",
        "      state = forget_gate * state + input_gate * tf.tanh(update) # state(t-1) --> state(t)\n",
        "      output_gate = tf.sigmoid(split3)\n",
        "    return output_gate * tf.tanh(state), state #returning output(t) and state(t)\n",
        " \n",
        "  # Input data.\n",
        "  train_data = list() #num_unrollings の展開はListで\n",
        "  \n",
        "  with tf.name_scope(\"train_data\"):\n",
        "    for _ in range(num_unrollings + 1):\n",
        "      train_data.append(tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))\n",
        " \n",
        "  train_inputs = train_data[:num_unrollings]\n",
        "  train_labels = train_data[1:]  # labels are inputs shifted by one time step.\n",
        "  # num_unrollings = 3  ->  a, b, c, d \n",
        "  # train_inputs = a, b, c 　  0番目から2番目\n",
        "  # train_labels = b, c, d　  　1番目から3番目(最後)まで\n",
        "  print(\"train_data : \",train_data)\n",
        "\n",
        "  \n",
        "  # Unrolled LSTM loop.\n",
        "  outputs = list()\n",
        "  output = saved_output #????初期値は\n",
        "  state = saved_state\n",
        "  \n",
        "  with tf.name_scope(\"train_inputs\"):\n",
        "    for i in train_inputs: # a, b, c をインプットとして、アウトプットを全部計算する\n",
        "      output, state = lstm_cell(i, output, state)\n",
        "      outputs.append(output)\n",
        "\n",
        "  # State saving across unrollings. logitsとlossの前にsaveをする\n",
        "  with tf.control_dependencies([saved_output.assign(output), saved_state.assign(state)]):\n",
        "    # Classifier.\n",
        "    logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b) # アウトプットから一遍に推論するnp[bs x em]を unroll個縦に 繰り返し #これでクロスエントロピー求めて良い？\n",
        "#     loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(labels=tf.concat(train_labels, 0), logits=logits), name=\"loss\") #推論と正答の損失関数を計算する\n",
        "    loss = tf.reduce_mean( tf.square(tf.concat(train_labels, 0)- logits), name=\"loss\") #回帰のようなやり方\n",
        "    print(\"train_labels : \",train_labels)\n",
        "    print(\"labels=tf.concat(train_labels, 0) : \", tf.concat(train_labels, 0))\n",
        "    print(\"logits : \", logits)\n",
        "    print(\"loss : \", loss)\n",
        "\n",
        "  # Optimizer.\n",
        "  global_step = tf.Variable(0, name=\"global_step\")\n",
        "  with tf.name_scope(\"Optimize\"):  #意味\n",
        "    learning_rate = tf.train.exponential_decay(10.0, global_step, 5000, 0.1, staircase=True)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate) #learning_rateを入力として、optimizerを初期化する\n",
        "    gradients, v = zip(*optimizer.compute_gradients(loss)) #損失関数を入力として勾配とその変数を返す\n",
        "    print(\"v: \",v) #どの変数について最適化されたか\n",
        "    print(\"global_step: \",global_step) #どうやってインクリメントされるのか？\n",
        "    #pdb.set_trace()\n",
        "    gradients, _ = tf.clip_by_global_norm(gradients, 1.25) #勾配の長さを1.25に調整\n",
        "    optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n",
        "\n",
        "  # Predictions.\n",
        "  train_prediction = tf.nn.softmax(logits,name=\"Predictions\")\n",
        "  \n",
        "  # Sampling and validation eval: batch 1, no unrolling.\n",
        "  with tf.name_scope(\"Optimize\"):    \n",
        "    sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size]) #input\n",
        "    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
        "    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
        "    \n",
        "    # called from 10 timer veri\n",
        "    reset_sample_state = tf.group( \n",
        "        saved_sample_output.assign(tf.zeros([1, num_nodes])), \n",
        "        saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
        "    \n",
        "    sample_output, sample_state = lstm_cell( sample_input, saved_sample_output, saved_sample_state)\n",
        "    \n",
        "    with tf.control_dependencies([saved_sample_output.assign(sample_output), saved_sample_state.assign(sample_state)]):\n",
        "      sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b)) #called from 10 timer\n",
        "  \n",
        "  #TensorBoard\n",
        "  tf.summary.scalar('Loss', loss) # yをスカラーとして記録\n",
        "  merged = tf.summary.merge_all() # おまじない\n",
        "  logdir = \"./drive/ColabData/logdir\"\n",
        "#   if tf.gfile.Exists(logdir):\n",
        "#     tf.gfile.DeleteRecursively(logdir) # ./logdirが存在する場合削除\n",
        "  writer = tf.summary.FileWriter(logdir, graph) # 保存先を./logdirに設定"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data :  [<tf.Tensor 'train_data/Placeholder:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_1:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_2:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_3:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_4:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_5:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_6:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_7:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_8:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_9:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_10:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_11:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_12:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_13:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_14:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_15:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_16:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_17:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_18:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_19:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_20:0' shape=(64, 128) dtype=float32>]\n",
            "train_labels :  [<tf.Tensor 'train_data/Placeholder_1:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_2:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_3:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_4:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_5:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_6:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_7:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_8:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_9:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_10:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_11:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_12:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_13:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_14:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_15:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_16:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_17:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_18:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_19:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'train_data/Placeholder_20:0' shape=(64, 128) dtype=float32>]\n",
            "labels=tf.concat(train_labels, 0) :  Tensor(\"concat_2:0\", shape=(1280, 128), dtype=float32)\n",
            "logits :  Tensor(\"xw_plus_b:0\", shape=(1280, 128), dtype=float32)\n",
            "loss :  Tensor(\"loss:0\", shape=(), dtype=float32)\n",
            "v:  (<tf.Variable 'big_x:0' shape=(128, 1024) dtype=float32_ref>, <tf.Variable 'big_m:0' shape=(256, 1024) dtype=float32_ref>, <tf.Variable 'big_b:0' shape=(1, 1024) dtype=float32_ref>, <tf.Variable 'w:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'global_step:0' shape=() dtype=int32_ref>)\n",
            "global_step:  <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KyVd8FxT5QBc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocabulary_size = embedding_size #1-hotの代わりab_em_vectorを使う\n",
        "\n",
        "def logprob(predictions, labels):\n",
        "#   Log-probability of the true labels in a predicted batch.\n",
        "#   predictions ｂｓ個の出力 emベクトル、softmaxで確率に\n",
        "#   labels ?\n",
        "  predictions[predictions < 1e-10] = 1e-10\n",
        "  return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
        "\n",
        "def sample_distribution(distribution):\n",
        "#   prediction[0] は　長さ 1のランダムなvoc要素数の１次元配列\n",
        "#   Sample one element from a distribution assumed to be an array of normalized  probabilities.\n",
        "#   結果的に0 から　voc-1 の整数をランダムに生成\n",
        "  r = random.uniform(0, 1)\n",
        "  s = 0\n",
        "  for i in range(len(distribution)):\n",
        "    s += distribution[i]\n",
        "    if s >= r:\n",
        "      return i\n",
        "  return len(distribution) - 1\n",
        "\n",
        "def sample(prediction): #ランダムな文字を　 1-hot で返す　=> abベクトル\n",
        "  # Turn a (column) prediction into 1-hot encoded samples.\n",
        "  # prediction ?\n",
        "  p = np.zeros(shape=[1, vocabulary_size0], dtype=np.float)\n",
        "  p[0, sample_distribution(prediction[0])] = 1.0\n",
        "  return p\n",
        "\n",
        "def random_distribution():\n",
        "  # 長さ 1のランダムなvoc要素数の横ベクトル \n",
        "  b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size0])\n",
        "#   c =  b/np.sum(b, 1)[:, None]\n",
        "  c =  b/np.sum(b, 1)\n",
        "#   pdb.set_trace()\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RD9zQCZTEaEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4823
        },
        "outputId": "a141658a-ab41-4f49-99cd-ee60eef24c83"
      },
      "cell_type": "code",
      "source": [
        "num_steps = 7001 #7001\n",
        "summary_frequency = 100\n",
        "\n",
        "with tf.Session(graph=graph) as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "  print('Initialized')\n",
        "  mean_loss = 0\n",
        "  \n",
        "  for step in range(num_steps):\n",
        "    \n",
        "    batches = train_batches.next() ### ＜train_batches＞ の利用先\n",
        "    \n",
        "    feed_dict = dict()\n",
        "    for i in range(num_unrollings + 1): \n",
        "      feed_dict[train_data[i]] = batches[i]  #何を入れて学習させたか　追ってみる\n",
        "      \n",
        "    summary, _, l, predictions, lr = session.run( [merged, optimizer, loss, \n",
        "                         train_prediction, learning_rate], feed_dict=feed_dict)\n",
        "    \n",
        "    #predictions = np 80,128   80 = bs x unr 　を np(bs, em)に分解 \n",
        "    pred_batches = list()  #   bs x em のリスト\n",
        "    for unr in range(num_unrollings) : \n",
        "      pred_batches.append(predictions[0 + unr : batch_size + unr,:])\n",
        "\n",
        "    mean_loss +=  l\n",
        "    #print(\"mean_loss\", mean_loss, \"l\", l,\"feed_dict\",feed_dict,\"predictions\",predictions)\n",
        "    \n",
        "    if step % summary_frequency == 0:\n",
        "      if step > 0:\n",
        "        mean_loss = mean_loss / summary_frequency\n",
        "      # The mean loss is an estimate of the loss over the last few batches.\n",
        "      print(\n",
        "        'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
        "      mean_loss = 0\n",
        "      labels = np.concatenate(list(batches)[1:])\n",
        "      print('Minibatch perplexity: %.2f' % float(\n",
        "        np.exp(logprob(predictions, labels))))\n",
        "    \n",
        "      writer.add_summary(summary, step) #TB\n",
        "      \n",
        "      if step % (summary_frequency * 10) == 0:\n",
        "        # Generate some samples.\n",
        "        print('=' * 80)\n",
        "        \n",
        "        for _ in range(1):  #(5)\n",
        "          \n",
        "          char1 = 'j'\n",
        "#           char1 = valid_text[random.randint(0, 999)]  #乱数やめてみる?\n",
        "#           char2 = valid_text[random.randint(0, 999)]\n",
        "          char2 = 't'\n",
        "          \n",
        "          feed =  char2ab_vec_np_em_1( char1, char2).T  #ab形式 2文字のem形式\n",
        "          sentence = char1 + char2  #   先頭にセット\n",
        "          #pdb.set_trace()\n",
        "          reset_sample_state.run()  #ネット状態の初期化\n",
        "          \n",
        "          for _ in range(79):   #前の文字abから次の文字cdを予想、これを文にれんけつし、79回繰り返す\n",
        "            prediction = sample_prediction.eval( {sample_input: feed} )\n",
        "            sentence += np_bs_em2ab_li_bs(prediction)[0] \n",
        "#             pdb.set_trace()\n",
        "          print(sentence)\n",
        "      \n",
        "    #トレーニングデータを印刷\n",
        "        print(\"inp\",batches2string( batches[0:num_unrollings]), \"ans\",batches2string( batches[1:]), \n",
        "#         print(\"inp\",batches2string( train_data[0:num_unrollings].eval), \"ans\",batches2string( batches[1:]), \n",
        "              \"pre\", batches2string(pred_batches) ) \n",
        "          \n",
        "        print('=' * 80)\n",
        "      # Measure validation set perplexity.\n",
        "      reset_sample_state.run()\n",
        "      valid_logprob = 0\n",
        "      for _ in range(valid_size):\n",
        "        b = valid_batches.next()\n",
        "        predictions = sample_prediction.eval({sample_input: b[0]})\n",
        "        valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
        "      print('Validation set perplexity: %.2f' % float(np.exp(\n",
        "        valid_logprob / valid_size)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Average loss at step 0: 17.217966 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.05\n",
            "================================================================================\n",
            "jtawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft rawft raw\n",
            "inp ['onomous individuals mutual aid and self ', 'errorism in the late one nine six zero s', 'chaeological sites in the united states ', 'ations abbeys art history the annales sc', 'leonora of aquitaine in one two zero eig', 'ring his interrogations after the war an', 'spoken by small isolated communities thr', 'e four th january one nine three eight a', 'ite this incident atlanta s political an', 'nds of refugees from guatemala and el sa', 'de accugroove loudpeakers acme loudpeake', 'as the seven five seven its narrowbody s', ' the thirty and the three all the warrio', 'al science sense he is well known for hi', 'achievement or service while of lesser d', 'forehand the set of cards dealt to a pla', 'igher proportion of its economy than jer', 'roughout his works dickens retained an e', 'rhodes eds g rard deledalle gen ed mouto', 'ts whether there was a first event in th', 'onal citizenship in recent years some in', ' solutes in non frozen solution during f', 'algorithm to understand this intuitively', 'otion to god almighty hume accedes and t', 'ased ability to perform simple cognitive', 'ded nondeterminism scalability a scalabl', ' days of sodom written in one seven eigh', 'es is uncertain it could have referred t', 'this reason many countries ensure equal ', 'ent e mail clients use their own proprie', ' of past traditions could be classified ', 'o very as he has been quoted the album g', 'tures can connect to computers can be us', 'oanalytique one nine eight nine he insis', ' zero th day of the year in the gregoria', 'a qualified f one four pilot a modified ', 'special relativity are lumped together h', 'mentally damaging pesticides subsequentl', 'e specialized topics nuclear and particl', 're the great flood and that the geograph', 'rence it also gives parliament the right', 's having originally been a persian word ', 'nic oscillators at least approximately s', ' the most prevalent are subtypes b found', 'escendant of latin some seven five of it', 'med of the operation the tower commissio', 'ro eight zero six one one one seven two ', 'their altix machines in jan two zero zer', 't seven in a snowstorm at fort keogh mon', 'eased by suggesting litigation over post', 'but with the state occupying a large rol', ' knitting machine in action a piece of k', 'bermeister had knowingly allowed kazaa u', 'ing of the american occupation he served', 'ority in parliament in the two three may', 'in latin but each produced a body of lat', 'tuning peg as if it were a watch to the ', 'el michiel ed encyclopaedia of mathemati', 'n and air defense of the republic of mac', 'tered by the american midwifery certific', 'april two eight june two eight listing o', 'one eight six four by appointment of u s', 'cosmography also allowed mahayana to be ', 'bility to support multiple service model'] ans ['omous individuals mutual aid and self go', 'rorism in the late one nine six zero s a', 'aeological sites in the united states gr', 'ions abbeys art history the annales scho', 'onora of aquitaine in one two zero eight', 'ng his interrogations after the war and ', 'oken by small isolated communities throu', 'four th january one nine three eight a s', 'e this incident atlanta s political and ', 's of refugees from guatemala and el salv', ' accugroove loudpeakers acme loudpeakers', ' the seven five seven its narrowbody sis', 'he thirty and the three all the warriors', ' science sense he is well known for his ', 'hievement or service while of lesser deg', 'rehand the set of cards dealt to a playe', 'her proportion of its economy than jerse', 'ughout his works dickens retained an emp', 'odes eds g rard deledalle gen ed mouton ', ' whether there was a first event in the ', 'al citizenship in recent years some inte', 'olutes in non frozen solution during fre', 'gorithm to understand this intuitively c', 'ion to god almighty hume accedes and the', 'ed ability to perform simple cognitive f', 'd nondeterminism scalability a scalable ', 'ays of sodom written in one seven eight ', ' is uncertain it could have referred to ', 'is reason many countries ensure equal ai', 't e mail clients use their own proprieta', 'f past traditions could be classified as', 'very as he has been quoted the album gen', 'res can connect to computers can be used', 'nalytique one nine eight nine he insists', 'ero th day of the year in the gregorian ', 'qualified f one four pilot a modified si', 'ecial relativity are lumped together her', 'ntally damaging pesticides subsequently ', 'specialized topics nuclear and particle ', ' the great flood and that the geographic', 'nce it also gives parliament the right t', 'having originally been a persian word fo', 'c oscillators at least approximately sol', 'he most prevalent are subtypes b found p', 'cendant of latin some seven five of ital', 'd of the operation the tower commission ', ' eight zero six one one one seven two ze', 'eir altix machines in jan two zero zero ', 'seven in a snowstorm at fort keogh monta', 'sed by suggesting litigation over post p', 't with the state occupying a large role ', 'nitting machine in action a piece of kni', 'rmeister had knowingly allowed kazaa use', 'g of the american occupation he served i', 'ity in parliament in the two three may o', ' latin but each produced a body of latin', 'ning peg as if it were a watch to the ac', ' michiel ed encyclopaedia of mathematics', 'and air defense of the republic of maced', 'red by the american midwifery certificat', 'ril two eight june two eight listing of ', 'e eight six four by appointment of u s p', 'smography also allowed mahayana to be qu', 'lity to support multiple service models '] pre [' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r raw', ' r r r r r r r r r r r r r r r r r rawaw', ' r r r r r r r r r r r r r r r r rawaw r', ' r r r r r r r r r r r r r r r rawaw r r', ' r r r r r r r r r r r r r r rawaw r r r', ' r r r r r r r r r r r r r rawaw r r r r', ' r r r r r r r r r r r r rawaw r r r r r', ' r r r r r r r r r r r rawaw r r r r r r', ' r r r r r r r r r r rawaw r r r r r r r', ' r r r r r r r r r rawaw r r r r r r r r', ' r r r r r r r r rawaw r r r r r r r r r', ' r r r r r r r rawaw r r r r r r r r r r', ' r r r r r r rawaw r r r r r r r r r r r', ' r r r r r rawaw r r r r r r r r r r raw', ' r r r r rawaw r r r r r r r r r r raw r', ' r r r rawaw r r r r r r r r r r raw r r', ' r r rawaw r r r r r r r r r r raw r rpb', ' r rawaw r r r r r r r r r r raw r rpbft', ' rawaw r r r r r r r r r r raw r rpbft r', 'awaw r r r r r r r r r r raw r rpbft raw', 'aw r r r r r r r r r r raw r rpbft rawaw', ' r r r r r r r r r r raw r rpbft rawaw r', ' r r r r r r r r r raw r rpbft rawaw r r', ' r r r r r r r r raw r rpbft rawaw r raw', ' r r r r r r r raw r rpbft rawaw r raw r', ' r r r r r r raw r rpbft rawaw r raw r r', ' r r r r r raw r rpbft rawaw r raw r r r', ' r r r r raw r rpbft rawaw r raw r r r r', ' r r r raw r rpbft rawaw r raw r r r raw', ' r r raw r rpbft rawaw r raw r r r raw r', ' r raw r rpbft rawaw r raw r r r raw raw', ' raw r rpbft rawaw r raw r r r raw raw r']\n",
            "================================================================================\n",
            "Validation set perplexity: 1.28\n",
            "Average loss at step 100: 1.550341 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.99\n",
            "Validation set perplexity: 1.27\n",
            "Average loss at step 200: 0.007961 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.70\n",
            "Validation set perplexity: 1.27\n",
            "Average loss at step 300: 0.007918 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.93\n",
            "Validation set perplexity: 1.27\n",
            "Average loss at step 400: 0.007895 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.75\n",
            "Validation set perplexity: 1.27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss at step 500: 0.007880 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.72\n",
            "Validation set perplexity: 1.27\n",
            "Average loss at step 600: 0.007866 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.96\n",
            "Validation set perplexity: 1.27\n",
            "Average loss at step 700: 0.007853 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.12\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 800: 0.007842 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.02\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 900: 0.007831 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.78\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1000: 0.007819 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.08\n",
            "================================================================================\n",
            "jt r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r\n",
            "inp ['erently litist the following figures are', 'r english language intellectual life in ', 'to the summit joshua however was admitte', ' controlled calculator known best as the', ' castile who should have been his brothe', ' rope with a loop on the end is placed o', 'th version of the periodic table shows t', 'ucouleurs french astronomer d one nine n', ' clark being openly critical of american', 'a significant portion of national revenu', 'nyman and john cage at this time he was ', ' the american league he went two three o', 'e traditional one at jerusalem jeroboam ', 'f a massive star cluster that has been s', ' handles finances of yeltsin s family on', 'ates many t shirts are available that di', 'thodox and the monophysites became the c', 'le s republic of china capital punishmen', ' her death in one eight three nine gauss', 'one one substances were controlled under', 'o five hours after r s impact anticipati', 'l on groups they see as cults jack chick', 'se it is convenient to introduce a regul', 'he united states constitution and so vot', 'd poppies in both hands idyll vii one fi', 'ming more popular among the engineering ', 'he fiercest in sports during one game a ', 'mportant motivators in much of recent ec', 'anagrams the letters of each word are so', ' longer period mainly prehistoric as in ', 't nine imperial household law fixed the ', 'al halichoerus grypus pinnipeds espionag', 'coasts florida leads the nation in torna', 'nitive rejection by patriarch gregory an', 'an actor b one nine three seven holidays', 'equires a hydrogen carrier typically fos', 'ds list of genealogy message boards arch', 't affect the amino acid s hydrophilic hy', 'yed the main characters in his early nov', 'rit awards in two zero zero two and agai', ' throne to his son after winning but not', 'many during the hyperinflation of one ni', ' rival clans and intrusions by the serbs', ' works are popularly referred to as lemo', ' hindustani music classification the ins', ' made of a thick layer of leather or nyl', 'e object polymorphism dynamic scoping li', 'is either zero or a prime number if r is', 'eaty of tordesillas which divides the ne', 'one six two one one six nine nine obadia', 're psychopathic nor do they differ in fr', 'r there is little evidence that these hi', 'idency present day maharashtra and the e', 'he integrity of the holiday which is par', 't zero five zero one one five six four y', ' characteristics llama head the followin', 'inding sites for runx one have also been', 'eontologists at the american museum of n', 'with europe especially france germany an', 't known must not have been performed in ', 'ctor producer and writer b one nine zero', ' young prince with an enduring zeal for ', ' g molarity and molality yield dimension', 'the athenians who were jealous of the vi'] ans ['ently litist the following figures are e', 'english language intellectual life in th', ' the summit joshua however was admitted ', 'ontrolled calculator known best as the h', 'astile who should have been his brother ', 'ope with a loop on the end is placed ove', ' version of the periodic table shows the', 'ouleurs french astronomer d one nine nin', 'lark being openly critical of american j', 'significant portion of national revenues', 'man and john cage at this time he was al', 'he american league he went two three one', 'traditional one at jerusalem jeroboam pr', 'a massive star cluster that has been str', 'andles finances of yeltsin s family on f', 'es many t shirts are available that dire', 'odox and the monophysites became the cau', ' s republic of china capital punishment ', 'er death in one eight three nine gauss h', 'e one substances were controlled under t', 'five hours after r s impact anticipation', 'on groups they see as cults jack chick c', ' it is convenient to introduce a regulat', ' united states constitution and so voted', 'poppies in both hands idyll vii one five', 'ng more popular among the engineering se', ' fiercest in sports during one game a br', 'ortant motivators in much of recent econ', 'agrams the letters of each word are sort', 'onger period mainly prehistoric as in ge', 'nine imperial household law fixed the su', ' halichoerus grypus pinnipeds espionage ', 'asts florida leads the nation in tornado', 'tive rejection by patriarch gregory and ', ' actor b one nine three seven holidays a', 'uires a hydrogen carrier typically fossi', ' list of genealogy message boards archiv', 'affect the amino acid s hydrophilic hydr', 'd the main characters in his early novel', 't awards in two zero zero two and again ', 'hrone to his son after winning but not i', 'ny during the hyperinflation of one nine', 'ival clans and intrusions by the serbs p', 'orks are popularly referred to as lemon ', 'industani music classification the instr', 'ade of a thick layer of leather or nylon', 'object polymorphism dynamic scoping list', ' either zero or a prime number if r is a', 'ty of tordesillas which divides the new ', 'e six two one one six nine nine obadiah ', ' psychopathic nor do they differ in from', 'there is little evidence that these hits', 'ency present day maharashtra and the ers', ' integrity of the holiday which is parti', 'zero five zero one one five six four yea', 'haracteristics llama head the following ', 'ding sites for runx one have also been f', 'ntologists at the american museum of nat', 'th europe especially france germany and ', 'known must not have been performed in th', 'or producer and writer b one nine zero z', 'oung prince with an enduring zeal for th', ' molarity and molality yield dimensional', 'e athenians who were jealous of the vict'] pre [' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r']\n",
            "================================================================================\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1100: 0.007811 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.74\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1200: 0.007802 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.84\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1300: 0.007790 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.77\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1400: 0.007792 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1500: 0.007780 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.01\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1600: 0.007768 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.65\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1700: 0.007768 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.94\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1800: 0.007758 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.19\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 1900: 0.007754 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.82\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2000: 0.007749 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.79\n",
            "================================================================================\n",
            "jt r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r\n",
            "inp ['y two zero zero one one five epub two ze', 's and a wraparound jacket usually white ', 'e first launch of a space shuttle columb', 'uby greg stein chairman sander striker h', 've survived all out war incl a nuclear a', 'her name for the entrance level usually ', ' of pakistan b one nine one seven one ni', 'e prominence of the abhidhamma has varie', 'to discover that without it testing prov', 'ometer of the highway went through bosni', ' of the day included a military review i', 'them in the one nine two six series the ', 'e of any worth to babylon including the ', 'his is the decision cycle every decision', 'isplay at fantasy of flight memphis bell', ' gun muzzles dry and being a membrane to', 'direct democracy is the best form of gov', 'e about one of the dissolved carbon diox', 'toms became worse historians agree that ', 'ister edith born in one eight eight nine', 'dditional information cdc also publish t', 's were forbidden to use writing to recor', 'es to the contract makes a promise or pr', 'pages by iyoway jp downloadable dictiona', 'suite entitled burlesque don quixotte in', 'ymphony he also began his satirical oper', 'ism and statism including but not limite', 'on comfortably orbits in an inertial ref', 'f the one nine nine zero s which gradual', 'ng the proper motion of a star in the se', 'ese annexation on two nine august one ni', 'ght five as inept magician rosco de vill', 't in this equation f t is the instantane', ' ernest tyldesley british cricketer d on', 'ne zero whereas one e one zero zero one ', ' blown a life long fan of science fictio', 'pective palestinian state demographics a', 'ome mystical scientific and religious pr', 'ged instrument players can effect an ext', ' threatened to destroy the earth on seve', 'ems inc he currently two zero zero five ', 'oolidge administration hoover s stance o', 'wsom and dee carstensen have separately ', 'a flash player plugin its local shared o', 'or the u s air force that recommended pa', 'patients e g aids serology can be troubl', 'terlingua were initially published in on', 's translation development the internet p', 'itish field marshal d one seven nine six', 'ough and deep fried making kare pan curr', ' new york where she recorded tracks for ', ' the rocket exploding in the end is a mo', ' looking for klm as related to human com', 'ks k meleon home page k meleon official ', 'nd military commanders are frequently sh', 'ept notebooks as a private journal inten', 'g an organised no nonsense efficient bus', 'n also be used to catch mice mice cannot', 'too strong a two thirds majority like i ', 'ron oxide nanoparticles have become avai', 'e uncovered a layer of sediment leaving ', 'place midi with incompatible but very si', 'ter b one four eight nine one five three', 'ed up with mac os x v one zero two jagua'] ans ['two zero zero one one five epub two zero', 'and a wraparound jacket usually white in', 'first launch of a space shuttle columbia', 'y greg stein chairman sander striker his', ' survived all out war incl a nuclear att', 'r name for the entrance level usually as', 'f pakistan b one nine one seven one nine', 'prominence of the abhidhamma has varied ', ' discover that without it testing proved', 'eter of the highway went through bosnia ', 'f the day included a military review in ', 'em in the one nine two six series the ca', 'of any worth to babylon including the ar', 's is the decision cycle every decision m', 'play at fantasy of flight memphis belle ', 'un muzzles dry and being a membrane to k', 'rect democracy is the best form of gover', 'about one of the dissolved carbon dioxid', 'ms became worse historians agree that th', 'ter edith born in one eight eight nine a', 'itional information cdc also publish the', 'were forbidden to use writing to record ', ' to the contract makes a promise or prom', 'ges by iyoway jp downloadable dictionari', 'ite entitled burlesque don quixotte in o', 'phony he also began his satirical opera ', 'm and statism including but not limited ', ' comfortably orbits in an inertial refer', 'the one nine nine zero s which gradually', ' the proper motion of a star in the sear', 'e annexation on two nine august one nine', 't five as inept magician rosco de ville ', 'in this equation f t is the instantaneou', 'rnest tyldesley british cricketer d one ', ' zero whereas one e one zero zero one ze', 'lown a life long fan of science fiction ', 'ctive palestinian state demographics aro', 'e mystical scientific and religious pred', 'd instrument players can effect an extre', 'hreatened to destroy the earth on severa', 's inc he currently two zero zero five li', 'lidge administration hoover s stance on ', 'om and dee carstensen have separately es', 'flash player plugin its local shared obj', ' the u s air force that recommended pack', 'tients e g aids serology can be troubles', 'rlingua were initially published in one ', 'translation development the internet pro', 'ish field marshal d one seven nine six o', 'gh and deep fried making kare pan curry ', 'ew york where she recorded tracks for go', 'he rocket exploding in the end is a modi', 'ooking for klm as related to human compu', ' k meleon home page k meleon official fo', ' military commanders are frequently shuf', 't notebooks as a private journal intenti', 'an organised no nonsense efficient busin', 'also be used to catch mice mice cannot s', 'o strong a two thirds majority like i en', 'n oxide nanoparticles have become availa', 'uncovered a layer of sediment leaving se', 'ace midi with incompatible but very simi', 'r b one four eight nine one five three n', ' up with mac os x v one zero two jaguar '] pre [' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r']\n",
            "================================================================================\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2100: 0.007739 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.75\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2200: 0.007728 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.84\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2300: 0.007727 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.68\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2400: 0.007724 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2500: 0.007717 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.72\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2600: 0.007708 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.88\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2700: 0.007704 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.96\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2800: 0.007698 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.89\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 2900: 0.007694 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.94\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 3000: 0.007688 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.93\n",
            "================================================================================\n",
            "jt r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r\n",
            "inp ['tarting to be set on fire by the trojan ', 'ompared an adult playing a child occurs ', 'r konstantin aseev russian chess player ', 's and operating voltages were compatible', 'en zero first earth day celebrated one n', 'njecture on tamagawa numbers proved resi', 'ional black mesa research facility is ge', 'tc in version two zero zero six autocad ', 'a one zero is now compatible with night ', 'ero zero zero tourists visiting annually', 'the city centre both west and east inste', 't length barge pole typically the length', 'nt has resisted public pressure to retur', ' seals it off a nest may consist of nume', 'in but readings of historical sources su', 'rganisms not related closely to any of t', 'have started eating himself gnawing at h', ' of two three years and appears to have ', 'art bbc series shown on bbc two in one n', 'thonic in scotland scots gaelic survives', 'gdp per capita two six five five zero tw', ' in the alternative history science fict', 'the baltics armenia georgia and moldova ', 'he billboard book of rock arranging isbn', 'r the yale daily news beginning septembe', 'anies as well who released their own gam', 'en metallic or rubber mute can be attach', 'of the eiffel tower free photo gallery o', 'cle s position the less accurately we ca', 'resbyter acting in the person of christ ', 'eth the queen assumed the title supreme ', ' subject in peer reviewed journals is a ', ' one seven nine seven one eight nine thr', 'm in addition to this propagandists comm', ' was a greek translation created at alex', 'ive near water or in marshes but cannot ', 'a military news georgia military flags t', 'use and continuous fields rain fall amou', 'p cavalry raids in the latter years of t', 'r funding consensus is further compromis', 'onia became the symbol of the city s spi', 'the one nine eight zero s technologies w', ' on the threshold of the aqsa mosque and', ' zero th century that there was a true b', ' punishments the scroll i am the master ', 'ams of various heavenly figures includin', 'general connacht irish but since most co', 'ine three nine to one nine four five at ', 'president of the united states b one sev', ' halved whilst that of the united states', 'he audience s anticipation and then lett', 'cceptance of khazar coinage in foreign l', 'the sixth episode of the tenth season of', 'lli moving john anthony james oh england', 'vian team fc universitate riga by one on', ' color and has an index of refraction fr', ' west yorkshire and other operators to t', 'iews and commercials in the middle of li', 'ted at various strategic points moreover', 'ers and recording sessions for its natio', 'barbara cartland english author b one ni', 'at least the existence of a continuous f', 'nimal amount of beverages some followers', 'ndel the father of genetics boston hough'] ans ['rting to be set on fire by the trojan he', 'pared an adult playing a child occurs mo', 'konstantin aseev russian chess player b ', 'and operating voltages were compatible b', ' zero first earth day celebrated one nin', 'ecture on tamagawa numbers proved resist', 'nal black mesa research facility is gene', ' in version two zero zero six autocad ad', 'one zero is now compatible with night vi', 'o zero zero tourists visiting annually o', 'e city centre both west and east instead', 'length barge pole typically the length f', ' has resisted public pressure to return ', 'eals it off a nest may consist of numero', ' but readings of historical sources sugg', 'anisms not related closely to any of the', 've started eating himself gnawing at his', 'f two three years and appears to have at', 't bbc series shown on bbc two in one nin', 'onic in scotland scots gaelic survives o', 'p per capita two six five five zero two ', 'n the alternative history science fictio', 'e baltics armenia georgia and moldova bo', ' billboard book of rock arranging isbn z', 'the yale daily news beginning september ', 'ies as well who released their own games', ' metallic or rubber mute can be attached', ' the eiffel tower free photo gallery of ', 'e s position the less accurately we can ', 'sbyter acting in the person of christ in', 'h the queen assumed the title supreme go', 'ubject in peer reviewed journals is a st', 'ne seven nine seven one eight nine three', 'in addition to this propagandists common', 'as a greek translation created at alexan', 'e near water or in marshes but cannot li', 'military news georgia military flags two', 'e and continuous fields rain fall amount', 'cavalry raids in the latter years of the', 'funding consensus is further compromised', 'ia became the symbol of the city s spiri', 'e one nine eight zero s technologies we ', 'n the threshold of the aqsa mosque and p', 'ero th century that there was a true bre', 'unishments the scroll i am the master of', 's of various heavenly figures including ', 'neral connacht irish but since most conn', 'e three nine to one nine four five at th', 'esident of the united states b one seven', 'alved whilst that of the united states i', ' audience s anticipation and then lettin', 'eptance of khazar coinage in foreign lan', 'e sixth episode of the tenth season of f', 'i moving john anthony james oh england m', 'an team fc universitate riga by one one ', 'olor and has an index of refraction from', 'est yorkshire and other operators to the', 'ws and commercials in the middle of live', 'd at various strategic points moreover t', 's and recording sessions for its nationa', 'rbara cartland english author b one nine', ' least the existence of a continuous fun', 'mal amount of beverages some followers t', 'el the father of genetics boston houghto'] pre [' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r']\n",
            "================================================================================\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 3100: 0.007681 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.87\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 3200: 0.007675 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.01\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 3300: 0.007670 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.96\n",
            "Validation set perplexity: 1.26\n",
            "Average loss at step 3400: 0.007671 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.68\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set perplexity: 1.25\n",
            "Average loss at step 3500: 0.007665 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.10\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 3600: 0.007656 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.03\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 3700: 0.007663 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.82\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 3800: 0.007654 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.79\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 3900: 0.007650 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.99\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4000: 0.007645 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.75\n",
            "================================================================================\n",
            "jt r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r\n",
            "inp ['er i shall believe what i am doing hurts', 'ries in which abortion is legal require ', ' nine four eight one nine five one one n', ' up to nine zero from the bow is a stron', 'brosius with the welsh tradition of merl', 'xt or play from the latin word ag re mea', 'y television ad ad or ad may stand for a', ' the code is based on the chemical thera', 'helming what has not been observed is on', 'ld factbook two zero zero zero and the t', 'this movie the mr bungle song squeeze me', 'ills bacteria and preferably nothing els', ' and giraffes are wild browsers a shoppi', 'carlist rebel band grew the latter signe', 'dkerchief at the soldiers to indicate hi', 'erse of old inflation is exactly scale i', 'mbols were intended to be fully universa', 'action are equally affected types of cat', 'ussband one nine one nine for better for', 'stomization and professional services on', 'ied three times the famous biologist lyn', 'kie cookie monster cookie cutter cookie ', ' state of non existence knowing nothing ', 'ames such as dir and help and the name d', 'n as scatter dice the dice have arrows o', 'an impulse response or step response the', 'employed civilian labour force one three', 'solo sunny directed by konrad wolf and w', 'd quality of the release led to it being', 'eclipse eclipse html stunning solar and ', 'seven zero s as evidenced by his seven c', 'other techniques an individual vendor co', 'ce the introduction of mid engined cars ', 'ne ip address user pat spinler i don t l', 'viding self sustaining habitats for huma', 'fly into retirement f four phantom web r', 'e eight major tribes akan four four mosh', 'sphere during the past two zero years is', 'ff penny lane later on he attended the l', 'migrants return to the town from whereve', ' stereotypes about lgbt people e g dykes', 'indows three one x logo typical windows ', 'guided interface with new standard gadge', 'rs ferry west virginia site of john brow', 'g the euro currency system in january on', ' creek california four two winnemem wint', 'enerated the original ip packet the one ', 'ost to the international red cross memor', 'l stories one eight nine eight the unite', 'e three nine four one four seven seven c', 'ing cakung pasar rebo pondok pinang daan', 'nomic growth since two zero zero zero pa', ' sir julius caesar to sir paul mccartney', 'ue baseball american league kauffman sta', 'president antanas smetona opposed it and', 'ication unclear andromeda iv irregular g', 'isles lords of galloway wales rulers of ', 'etter control their lucrative fur tradin', ' km unpaved na km note mal has nine six ', 'hysicist nobel prize laureate d one nine', 'and rounds per minute not all chain guns', 'r meridiadocus or meriadocus among the p', 'e times slower than the pentium in float', ' wong born in vancouver bc one nine six '] ans [' i shall believe what i am doing hurts t', 'es in which abortion is legal require th', 'ine four eight one nine five one one nin', 'p to nine zero from the bow is a strong ', 'osius with the welsh tradition of merlin', ' or play from the latin word ag re meani', 'television ad ad or ad may stand for ad ', 'he code is based on the chemical therape', 'lming what has not been observed is one ', ' factbook two zero zero zero and the two', 'is movie the mr bungle song squeeze me m', 'ls bacteria and preferably nothing else ', 'nd giraffes are wild browsers a shopping', 'rlist rebel band grew the latter signed ', 'erchief at the soldiers to indicate his ', 'se of old inflation is exactly scale inv', 'ols were intended to be fully universal ', 'tion are equally affected types of catal', 'sband one nine one nine for better for w', 'omization and professional services on a', 'd three times the famous biologist lynn ', 'e cookie monster cookie cutter cookie ex', 'tate of non existence knowing nothing un', 'es such as dir and help and the name dot', 'as scatter dice the dice have arrows on ', ' impulse response or step response the o', 'ployed civilian labour force one three s', 'lo sunny directed by konrad wolf and wol', 'quality of the release led to it being w', 'lipse eclipse html stunning solar and lu', 'ven zero s as evidenced by his seven con', 'her techniques an individual vendor coul', ' the introduction of mid engined cars in', ' ip address user pat spinler i don t lik', 'ding self sustaining habitats for humani', 'y into retirement f four phantom web rel', 'eight major tribes akan four four moshi ', 'here during the past two zero years is d', ' penny lane later on he attended the liv', 'grants return to the town from wherever ', 'tereotypes about lgbt people e g dykes o', 'dows three one x logo typical windows th', 'ided interface with new standard gadgets', ' ferry west virginia site of john brown ', 'the euro currency system in january one ', 'reek california four two winnemem wintu ', 'erated the original ip packet the one wh', 't to the international red cross memoria', 'stories one eight nine eight the united ', 'three nine four one four seven seven cha', 'g cakung pasar rebo pondok pinang daan m', 'mic growth since two zero zero zero part', 'ir julius caesar to sir paul mccartney b', ' baseball american league kauffman stadi', 'esident antanas smetona opposed it and s', 'ation unclear andromeda iv irregular gal', 'les lords of galloway wales rulers of wa', 'ter control their lucrative fur trading ', 'm unpaved na km note mal has nine six km', 'sicist nobel prize laureate d one nine e', 'd rounds per minute not all chain guns u', 'meridiadocus or meriadocus among the per', 'times slower than the pentium in floatin', 'ong born in vancouver bc one nine six tw'] pre [' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r']\n",
            "================================================================================\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4100: 0.007645 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.99\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4200: 0.007645 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.86\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4300: 0.007636 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.15\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4400: 0.007636 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4500: 0.007630 learning rate: 10.000000\n",
            "Minibatch perplexity: 1.01\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4600: 0.007625 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.76\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4700: 0.007625 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.85\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4800: 0.007627 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.83\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 4900: 0.007622 learning rate: 10.000000\n",
            "Minibatch perplexity: 0.81\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5000: 0.007616 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.71\n",
            "================================================================================\n",
            "jt r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r\n",
            "inp [' peninsula of chalcidice in three eight ', 'ackled when an opponent pulls a flag off', 'ampionship currently champcars and the i', 'als see also solvated electron metallic ', 'o three sections chapters one and two lo', 'quent lengthy writings mathematical achi', 'lman h l hunt attempted to bring an nfl ', 'l it separately the software had to modi', ' antinomy by logical reasoning therefore', ' at present due to lack of funds rail li', 'f the process of replication transcripti', 'k letter followed by the genitive in lat', 'tinue playing under the ownership of a n', 'gebra which is a division algebra is iso', 'luctant policeman the other two films ar', 'ontally vertically or diagonally as in t', 'rms of autism to whom consciousness is a', 'd so spectral colors cannot be matched e', 'ologne hosted the two zero th and one of', 'llating the finger of the left hand up a', 'ed by your web browser some browsers are', 'o zero by which time it will be nearing ', 'stem individuals with decreased gastric ', 's of different helical forms non helical', 'the principal route of transportation fo', 'tory dead sea in the morning seen from m', 'undee ice arena the team participates in', 'enetic material usually dna or rna of a ', 'etween a hub and a switch appeared known', 'derstanding of abundance of these elemen', 's which can even cause skin cancer if th', 'd slot extrudes the air in organs the ai', 'ive role in organizing literary and soci', 'norway paraguay pakistan philippines sau', 'ty of this practice will face a five yea', ' a private law suit not government censo', 'uently dismissed unanimously the applica', 'luding a gumby s summer fun special a gu', 's the lunar triple goddess symbol goddes', 't one nine eight nine pass the buck nine', 'pinnaglobin only seen in the mollusk pin', ' a major part of the festival where loca', 'the country of one s origin there are sy', ' of one nine one two aimed primarily at ', ' zero seven three two one x four zero th', 'derstand specifically the similes used i', 'jordan israel gained control of the enti', 'ents was at first virtually unrecognized', 'est bus accident to date in hong kong bi', ' elections is ratified one nine six eigh', 'rick joseph cade ao january one eight on', 'deterioration of the republic s economy ', 'ot be replaced it is said that one shoul', ' and suggested it be applied to nupedia ', 'n may one two zero zero four since one n', 'he hillsides in combustible chaparral na', 's of sweden blekinge governors dalarna g', 'd receiving accredited training the mini', ' euro fiscal year calendar year see also', ' rational religious ethic of social cond', ' when a player moves onto free parking s', 'ts that the entry is invalid ballybackan', 'rict a unique mile long shopping distric', 'h century the city hosts the university '] ans ['eninsula of chalcidice in three eight fo', 'kled when an opponent pulls a flag off a', 'pionship currently champcars and the ind', 's see also solvated electron metallic so', 'three sections chapters one and two look', 'ent lengthy writings mathematical achiev', 'an h l hunt attempted to bring an nfl fr', 'it separately the software had to modify', 'ntinomy by logical reasoning therefore a', 't present due to lack of funds rail link', 'the process of replication transcription', 'letter followed by the genitive in latin', 'nue playing under the ownership of a new', 'bra which is a division algebra is isomo', 'ctant policeman the other two films are ', 'tally vertically or diagonally as in tic', 's of autism to whom consciousness is att', 'so spectral colors cannot be matched exa', 'ogne hosted the two zero th and one of t', 'ating the finger of the left hand up and', ' by your web browser some browsers are c', 'zero by which time it will be nearing th', 'em individuals with decreased gastric ac', 'of different helical forms non helical f', 'e principal route of transportation for ', 'ry dead sea in the morning seen from mas', 'dee ice arena the team participates in t', 'etic material usually dna or rna of a ce', 'ween a hub and a switch appeared known a', 'rstanding of abundance of these elements', 'which can even cause skin cancer if the ', 'slot extrudes the air in organs the air ', 'e role in organizing literary and social', 'rway paraguay pakistan philippines saudi', ' of this practice will face a five year ', ' private law suit not government censors', 'ntly dismissed unanimously the applicant', 'ding a gumby s summer fun special a gumb', 'the lunar triple goddess symbol goddesse', 'one nine eight nine pass the buck nine n', 'nnaglobin only seen in the mollusk pinna', ' major part of the festival where locals', 'e country of one s origin there are syno', 'f one nine one two aimed primarily at so', 'ero seven three two one x four zero thre', 'rstand specifically the similes used in ', 'rdan israel gained control of the entire', 'ts was at first virtually unrecognized b', 't bus accident to date in hong kong birt', 'lections is ratified one nine six eight ', 'ck joseph cade ao january one eight one ', 'terioration of the republic s economy du', ' be replaced it is said that one should ', 'nd suggested it be applied to nupedia an', 'may one two zero zero four since one nin', ' hillsides in combustible chaparral nati', 'of sweden blekinge governors dalarna gov', 'receiving accredited training the minimu', 'uro fiscal year calendar year see also m', 'ational religious ethic of social conduc', 'hen a player moves onto free parking sto', ' that the entry is invalid ballybackanow', 'ct a unique mile long shopping district ', 'century the city hosts the university of'] pre [' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r']\n",
            "================================================================================\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5100: 0.007616 learning rate: 1.000000\n",
            "Minibatch perplexity: 1.13\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5200: 0.007616 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.66\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5300: 0.007610 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.78\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5400: 0.007614 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5500: 0.007612 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.97\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5600: 0.007610 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.81\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5700: 0.007616 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.75\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5800: 0.007614 learning rate: 1.000000\n",
            "Minibatch perplexity: 1.10\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 5900: 0.007615 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.92\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 6000: 0.007615 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.90\n",
            "================================================================================\n",
            "jt r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r\n",
            "inp ['hree eight to present the jean hersholt ', 'ict arnold now a turncoat who had sold h', 'd capitalist ownership he was a staunch ', 'enda of ambrose than of theodosius in th', ' any position as an anglican clergyman m', 'e to be tolerated regardless of initial ', 'many more genes than exist in the genome', 'freedom where the anti ballistic missile', 'ries against domestic fascism this polic', ' former yugoslavia economy was communist', 'of binary numbers in computer systems pl', 'ere no longer desirable for the changing', 'tionary relationships bears are members ', 'at element is deleted a new separator fo', 'l procedures remarried indicates later m', 'd potatoes unlike the occasional use in ', 'esia and nyasaland pound rhodesia and ny', 'hree five years for about five zero six ', 'had a son william lewis herndon arthur w', ' five seven record meant the browns were', 'ortmanteau of functional and cyborg was ', 'eld in one nine seven five in england wi', 'st severe tests each singly identified b', 'mply democracy is the requirement for po', 'ng the top two five schools in the natio', 'ial from w three schools zvon dtd tutori', 'which is claimed by norway it consists o', 'ero zero zero sq mi or two zero of the e', 'nother two zero zero zero zero in one ei', 'cia com au reviews e event horizon shtml', ' works and various similarities between ', 'lm that makes up the majority of any fil', 'en four six to joseph goya and gracia lu', 'ition flying spins are spins that are in', 'the word element in finite element metho', 'the iq paradox resolved article by dicke', 'itory citizens after a short campaign gi', 'in tree structures thus favoring the use', 'board rebuilding the world trade center ', 'aver alan rickman and tony shalhoub the ', 'ieutenant general and held this rank on ', 'merican woman she did not get the role b', 'e paul oakenfold and danny rampling were', 'oduced the first original mathematics in', 's also have occasional internal contradi', 'lgar fraction in which the numerator and', 'f changing a light bulb quickies about l', 'our seven one one two zero one one six i', ' tsar of russia one eight one four franc', 'e vote and prevented carter from taking ', 'ander of the british empire national med', 'khstan is a member of the united nations', 'teachings indirectly through his own tea', 'illy and rock and roll and rap that has ', 'v aids adult prevalence rate zero one si', 'ngeles convention visitors bureau city a', 'ogy and the ability to use technology to', ' maintained as the result of any sort of', 'ption boosted by large increases in gove', ' ministry of finance ministry of transpo', 'to evolve and therefore adapt more quick', 'tian bauer not to be confused with the t', 'e from an infinite number of perspective', ' external links provigil corporate websi'] ans ['ee eight to present the jean hersholt hu', 't arnold now a turncoat who had sold his', 'capitalist ownership he was a staunch ad', 'da of ambrose than of theodosius in thre', 'ny position as an anglican clergyman mat', 'to be tolerated regardless of initial pr', 'ny more genes than exist in the genome i', 'eedom where the anti ballistic missile d', 'es against domestic fascism this policy ', 'ormer yugoslavia economy was communist a', ' binary numbers in computer systems plea', 'e no longer desirable for the changing p', 'onary relationships bears are members of', ' element is deleted a new separator for ', 'procedures remarried indicates later mar', 'potatoes unlike the occasional use in ja', 'ia and nyasaland pound rhodesia and nyas', 'ee five years for about five zero six ze', 'd a son william lewis herndon arthur who', 'ive seven record meant the browns were s', 'tmanteau of functional and cyborg was co', 'd in one nine seven five in england with', ' severe tests each singly identified by ', 'ly democracy is the requirement for poli', ' the top two five schools in the nation ', 'l from w three schools zvon dtd tutorial', 'ich is claimed by norway it consists of ', 'o zero zero sq mi or two zero of the ear', 'ther two zero zero zero zero in one eigh', 'a com au reviews e event horizon shtml p', 'orks and various similarities between ox', ' that makes up the majority of any film ', ' four six to joseph goya and gracia luci', 'ion flying spins are spins that are init', 'e word element in finite element method ', 'e iq paradox resolved article by dickens', 'ory citizens after a short campaign gibr', ' tree structures thus favoring the use o', 'ard rebuilding the world trade center fo', 'er alan rickman and tony shalhoub the mo', 'utenant general and held this rank on th', 'rican woman she did not get the role bec', 'paul oakenfold and danny rampling were b', 'uced the first original mathematics in e', 'also have occasional internal contradict', 'ar fraction in which the numerator and d', 'changing a light bulb quickies about lig', 'r seven one one two zero one one six in ', 'sar of russia one eight one four france ', 'vote and prevented carter from taking tr', 'der of the british empire national medal', 'stan is a member of the united nations o', 'achings indirectly through his own teach', 'ly and rock and roll and rap that has a ', 'aids adult prevalence rate zero one six ', 'eles convention visitors bureau city and', 'y and the ability to use technology to n', 'aintained as the result of any sort of a', 'ion boosted by large increases in govern', 'inistry of finance ministry of transport', ' evolve and therefore adapt more quickly', 'an bauer not to be confused with the thi', 'from an infinite number of perspectives ', 'xternal links provigil corporate website'] pre [' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r', ' r r r r r r r r r r r r r r r r r r r r']\n",
            "================================================================================\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 6100: 0.007615 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.73\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 6200: 0.007612 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.84\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 6300: 0.007610 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.82\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 6400: 0.007607 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.71\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set perplexity: 1.25\n",
            "Average loss at step 6500: 0.007610 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.77\n",
            "Validation set perplexity: 1.25\n",
            "Average loss at step 6600: 0.007610 learning rate: 1.000000\n",
            "Minibatch perplexity: 0.87\n",
            "Validation set perplexity: 1.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a1416facd35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     summary, _, l, predictions, lr = session.run( [merged, optimizer, loss, \n\u001b[0;32m---> 18\u001b[0;31m                          train_prediction, learning_rate], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#predictions = np 80,128   80 = bs x unr 　を np(bs, em)に分解\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Y5tapX3kpcqZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Problem 3\n",
        "---------\n",
        "\n",
        "(difficult!)\n",
        "\n",
        "Write a sequence-to-sequence LSTM which mirrors all the words in a sentence. For example, if your input is:\n",
        "\n",
        "    the quick brown fox\n",
        "    \n",
        "the model should attempt to output:\n",
        "\n",
        "    eht kciuq nworb xof\n",
        "    \n",
        "Refer to the lecture on how to put together a sequence-to-sequence model, as well as [this article](http://arxiv.org/abs/1409.3215) for best practices.\n",
        "\n",
        "---"
      ]
    }
  ]
}